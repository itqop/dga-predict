# 3 Сессия
## Команда Cerebro: Власов Глеб, Калентьев Леон, Арустамян Александр

<!-- #region -->
В 3-eй сессии были исследованы 3 модели: бинарные LSTM, GRU и multi SGD classifier

Значение batch_size установлено равным 32, количество эпох 20.


**GRU** - это улучшенная версия стандартной RNN, которая решает пробелую затухающего градиента. В GRU нет состояния ячейка, она использует скрытые состояния.
Обученная модель показала результаты:
1. average_precision_score: 0.8882406780150595
2. roc_auc_score: 0.9109137356745383
Гру быстрее работает, но даёт меньший результат


**LSTM** - тип RNN с ячейкой памяти, идеально подходит для данной проблемы, т.к. мы передаем последовательность символов, которую необходимо помнить.
Обученная модель показала результаты:
1. average_precision_score: 0.9219379878630435
2. roc_auc_score: 0.9471460694807483
Более долги процессинг, но результат более точный

Для работы с бинарной версией датасета было принято решение использовать LSTM

**SGD classifier** 
1. average_precision_score: 0.971
2. roc_auc_score: 0.998
Было принято решение разделить датасет из 90000 строк на 70000 для обучения и внутреннего тестирования и 20000 для отдельного тестирования.
Чтобы проверить работу, можно убрать комментарий на последней строчке и ввести сайт вручную, либо же оставить как есть, но перед тем, как загружать тестовый датасет его нужно подготовить (все функции написаны, отсутствие автоматизации связано с нехваткой времени)
<!-- #endregion -->

# Образ Docker для Tensorflow
1. cerebro-dga/
2. docker run --gpus all -p 9999:8888 -it --rm -v /cerebro-dga:/app nvcr.io/nvidia/tensorflow:21.11-tf2-py3

```python

```
